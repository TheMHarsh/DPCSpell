# -*- coding: utf-8 -*-
"""PreviousEditDistanceBasedSpellChecker.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kp3C18yaWmfhKJU_8294UKqfHrmLA1Ow
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import metrics
from tqdm import tqdm
import warnings as wrn

wrn.filterwarnings('ignore')

def editDistance(str1, str2, m, n):
    if m == 0:
        return n
 
    if n == 0:
        return m
 
    if str1[m-1] == str2[n-1]:
        return editDistance(str1, str2, m-1, n-1)
 
    return 1 + min(editDistance(str1, str2, m, n-1),    # Insert
                   editDistance(str1, str2, m-1, n),    # Remove
                   editDistance(str1, str2, m-1, n-1)   # Replace
                )

# Dynamic Programming based
def editDistDP(str1, str2, m, n):
	# Create a table to store results of subproblems
	dp = [[0 for x in range(n + 1)] for x in range(m + 1)]

	# Fill d[][] in bottom up manner
	for i in range(m + 1):
		for j in range(n + 1):

			# If first string is empty, only option is to
			# insert all characters of second string
			if i == 0:
				dp[i][j] = j # Min. operations = j

			# If second string is empty, only option is to
			# remove all characters of second string
			elif j == 0:
				dp[i][j] = i # Min. operations = i

			# If last characters are same, ignore last char
			# and recur for remaining string
			elif str1[i-1] == str2[j-1]:
				dp[i][j] = dp[i-1][j-1]

			# If last character are different, consider all
			# possibilities and find minimum
			else:
				dp[i][j] = 1 + min(dp[i][j-1],	 # Insert
								dp[i-1][j],	 # Remove
								dp[i-1][j-1]) # Replace

	return dp[m][n]


# Driver code
# str1 = "sunday"
# str2 = "saturday"

# print(editDistDP(str1, str2, len(str1), len(str2)))
# This code is contributed by Bhavya Jain

df = pd.read_csv('./Dataset/corpus.csv')
# df

train_df, test_df = train_test_split(df, test_size=.15)
train_df, valid_df = train_test_split(train_df, test_size=.05)

# len(train_df), len(valid_df), len(test_df)

erroneous_words = []
actual_words = []
calculated_words = []

for i in tqdm(range(10000)):
    word = valid_df['Error'].values[i]
    # print(word)
    
    x = len(word)
    while True:
        temp_df = train_df['Word'].str.startswith(word[:x], na = False)
        temp_df = train_df[temp_df]
        if len(temp_df) != 0:
            break
        x -= 1
    
    if len(temp_df) > 100:
        temp_df = temp_df.sample(100)

    # print(temp_df)
    
    scores = []
    for temp_word in temp_df['Word'].values: 
        # score = editDistance(word, temp_word, len(word), len(temp_word))
        score = editDistDP(word, temp_word, len(word), len(temp_word))
        scores.append(score)
    
    temp_df['Scores'] = scores
    temp_df = temp_df.sort_values(by=['Scores'], ascending=True)

    calculated = temp_df.iloc[0, 0]
    
    act_word = valid_df['Word'].values[i]

    erroneous_words.append(word)
    calculated_words.append(calculated)
    actual_words.append(act_word)

    if i % 100 == 0 and i > 0:
        x = pd.DataFrame({
            'Error': erroneous_words,
            'Actual': actual_words,
            'Calculated': calculated_words
        })
        x.to_csv('./Dataset/ed_output.csv', index=False)
    

    # print(word, calculated)
    print(f"\n erroneous: {word}\n actual: {act_word}\n calculated: {calculated}")

words = []
for i in tqdm(range(len(df))):
    if df.iloc[i, 1] not in x['Error'].values:
        words.append(df.iloc[i, 0])

# x = pd.DataFrame({
#     'Error': erroneous_words,
#     'Actual': actual_words,
#     'Calculated': calculated_words
# })

acc_flags = []
for i in range(len(x)):
    if x.iloc[i, 1] == x.iloc[i, -1]:
        acc_flags.append(1)
    else:
        acc_flags.append(0)
x['EM'] = acc_flags

train_df = df
mod_acc_flags = []
for pred in x['Calculated'].values:
    if pred in words:
        mod_acc_flags.append(1)
    else:
        mod_acc_flags.append(0)
x['MA'] = mod_acc_flags

y_true = np.array(x['Actual'].values)
y_pred = np.array(x['Calculated'].values)

PR = metrics.precision_score(y_true, y_pred, average='weighted')
RE = metrics.recall_score(y_true, y_pred, average='weighted')
F1 = metrics.f1_score(y_true, y_pred, average='weighted')
F05 = metrics.fbeta_score(y_true, y_pred, average='weighted', beta=0.5)
ACC = metrics.accuracy_score(y_true, y_pred)

print(f'Accuracy = {ACC*100:.2f}%')
print(f'Precision = {PR:.4f}')
print(f'Recall = {RE:.4f}')
print(f'F1 Score = {F1:.4f}')
print(f'F0.5 Score = {F05:.4f}')



